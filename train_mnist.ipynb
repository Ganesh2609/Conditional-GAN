{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import torchinfo\n",
    "from WGAN import Generator, Discriminator, initialize_weights\n",
    "from ModelTrainer import train_models\n",
    "\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device agnostic code\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 1\n",
    "NUM_CLASSES = 10\n",
    "GEN_EMBEDDING = 256\n",
    "Z_DIM = 256\n",
    "NUM_EPOCHS = 4\n",
    "DISC_HIDDEN = 64\n",
    "GEN_HIDDEN = 64\n",
    "DISCRIMINATOR_ITERATIONS = 5\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "GENERATOR_SAVE_PATH = 'Models/mnist_first_generator.pth'\n",
    "DISCRIMINATOR_SAVE_PATH = 'Models/mnist_first_discriminator.pth'\n",
    "RESULT_PATH = 'Results/Train 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the transforms \n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "    transforms.Resize(size=IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*CHANNELS, std=[0.5]*CHANNELS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 938)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "\n",
    "train_data = datasets.MNIST(root='../DCGAN/dataset/', transform=input_transform, download=True)\n",
    "dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "len(train_data), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instances\n",
    "\n",
    "generator = Generator(latent_channels=Z_DIM, hidden_channels=GEN_HIDDEN, img_channels=CHANNELS, num_classes=NUM_CLASSES, img_size=IMAGE_SIZE, embed_size=GEN_EMBEDDING).to(device)\n",
    "initialize_weights(generator)\n",
    "\n",
    "discriminator = Discriminator(in_channels=CHANNELS, hidden_channels=DISC_HIDDEN, num_classes=NUM_CLASSES, img_size=IMAGE_SIZE).to(device)\n",
    "initialize_weights(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizers \n",
    "\n",
    "gen_opt = torch.optim.Adam(params=generator.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "disc_opt = torch.optim.Adam(params=discriminator.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "gen_scaler = torch.cuda.amp.GradScaler()\n",
    "disc_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A generator aleady exists... Loading that model and training it for the specified epochs\n",
      "A discriminator aleady exists... Loading that model and training it for the specified epochs\n"
     ]
    }
   ],
   "source": [
    "# Saving and loading models\n",
    "\n",
    "model_file = Path(GENERATOR_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    generator.load_state_dict(torch.load(f=GENERATOR_SAVE_PATH))\n",
    "    print(\"A generator aleady exists... Loading that model and training it for the specified epochs\")\n",
    "else:\n",
    "    print(\"A generator does not exist in the specified path... Creating the model and training it for the specified epochs\")\n",
    "    \n",
    "model_file = Path(DISCRIMINATOR_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    discriminator.load_state_dict(torch.load(f=DISCRIMINATOR_SAVE_PATH))\n",
    "    print(\"A discriminator aleady exists... Loading that model and training it for the specified epochs\")\n",
    "else:\n",
    "    print(\"A discriminator does not exist in the specified path... Creating the model and training it for the specified epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] : 100%|██████████| 938/938 [1:33:20<00:00,  5.97s/it, Gen Batch Loss=73.4, Gen Loss=76.3, Disc Batch Loss=6.95, Disc Loss=9.17]\n",
      "Epoch [3/5] : 100%|██████████| 938/938 [1:32:21<00:00,  5.91s/it, Gen Batch Loss=56.6, Gen Loss=66.9, Disc Batch Loss=9.21, Disc Loss=7.88]\n",
      "Epoch [4/5] : 100%|██████████| 938/938 [1:33:57<00:00,  6.01s/it, Gen Batch Loss=48.7, Gen Loss=54.6, Disc Batch Loss=10.9, Disc Loss=7.07]\n",
      "Epoch [5/5] : 100%|██████████| 938/938 [1:32:40<00:00,  5.93s/it, Gen Batch Loss=35.3, Gen Loss=38.8, Disc Batch Loss=9.67, Disc Loss=6.59]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Generator Loss': [76.26887828200611,\n",
       "  66.90160749716037,\n",
       "  54.643503237889014,\n",
       "  38.82902493100685],\n",
       " 'Discriminator Loss': [9.172338694143397,\n",
       "  7.875285068300487,\n",
       "  7.070296933401877,\n",
       "  6.5862765080893215]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model \n",
    "\n",
    "train_models(generator=generator,\n",
    "             discriminator=discriminator,\n",
    "             dataloader=dataloader,\n",
    "             gen_optimizer=gen_opt,\n",
    "             disc_optimizer=disc_opt,\n",
    "             gen_scaler=gen_scaler,\n",
    "             disc_scaler=disc_scaler,\n",
    "             BATCH_SIZE=BATCH_SIZE,\n",
    "             Z_DIM=Z_DIM,\n",
    "             NUM_EPOCHS=NUM_EPOCHS,\n",
    "             device=device,\n",
    "             DISC_ITERATIONS=DISCRIMINATOR_ITERATIONS,\n",
    "             LAMBDA_GP=LAMBDA_GP,\n",
    "             gen_path=GENERATOR_SAVE_PATH,\n",
    "             disc_path=DISCRIMINATOR_SAVE_PATH,\n",
    "             result_path=RESULT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
